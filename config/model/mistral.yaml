_target_: policy_model.MistralModel
config:
  model_name_or_path: /mnt/u14157_ic_nlp_001_files_nfs/nlpdata1/home/desabbat/projects/Rational_Metareasoning/models/Mistral-7B-v0.3
  generation_args:
    temperature: 0.0
    max_new_tokens: 512
    repetition_penalty: 1.0
    do_sample: False
    no_repeat_ngram_size: 0
  inference_mode: "cot"
  few_shot_path: "/mnt/u14157_ic_nlp_001_files_nfs/nlpdata1/home/desabbat/projects/Rational_Metareasoning/data/few_shot_prompts.json"
  instruction: false